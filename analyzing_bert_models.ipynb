{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matin\\Documents\\GitHub\\Examensarbete2025\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextClassificationPipeline, DistilBertTokenizer, DistilBertForSequenceClassification,AutoTokenizer, RobertaTokenizer, RobertaForSequenceClassification, BertForSequenceClassification, BertTokenizer, AlbertForSequenceClassification, AlbertTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/fake_or_real_news_cleaned.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv('datasets/WELFake_Dataset_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unbelievable obama s attorney general says mos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bobby jindal raised hindu uses story of christ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>satan russia unvelis an image of its terrifyin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>about time christian group sues amazon and spl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dr ben carson targeted by the irs i never had ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>house intel chair on trump russia fake story n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sports bar owner bans nfl games will show only...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>latest pipeline leak underscores dangers of da...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gop senator just smacked down the most punchab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>may brexit offer would hurt cost eu citizens e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  unbelievable obama s attorney general says mos...      1\n",
       "1  bobby jindal raised hindu uses story of christ...      0\n",
       "2  satan russia unvelis an image of its terrifyin...      1\n",
       "3  about time christian group sues amazon and spl...      1\n",
       "4  dr ben carson targeted by the irs i never had ...      1\n",
       "5  house intel chair on trump russia fake story n...      1\n",
       "6  sports bar owner bans nfl games will show only...      1\n",
       "7  latest pipeline leak underscores dangers of da...      1\n",
       "8  gop senator just smacked down the most punchab...      1\n",
       "9  may brexit offer would hurt cost eu citizens e...      0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6335 entries, 0 to 6334\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    6335 non-null   object\n",
      " 1   label   6335 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 99.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 71536 entries, 0 to 71535\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    71527 non-null  object\n",
      " 1   label   71536 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "original_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_path = r'models\\fake-news-roberta'\n",
    "bert_path = r'models\\fake-news-bert'\n",
    "albert_path = r'models\\fake-news-albert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_model = RobertaForSequenceClassification.from_pretrained(roberta_path, num_labels=2)\n",
    "bert_model = BertForSequenceClassification.from_pretrained(bert_path, num_labels=2)\n",
    "albert_model = AlbertForSequenceClassification.from_pretrained(albert_path, num_labels=2)\n",
    "\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained(roberta_path)\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "albert_tokenizer = AutoTokenizer.from_pretrained('albert-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = test_df['text'].tolist()\n",
    "true_labels = test_df['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [text[:1500] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict test dataset in batches\n",
    "batch_size = 2\n",
    "predicted_labels = []\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch_texts = texts[i:i + batch_size]\n",
    "    inputs = roberta_tokenizer(batch_texts, padding=True, truncation=True, return_tensors='pt')\n",
    "    outputs = roberta_model(**inputs)\n",
    "\n",
    "    logits = outputs.logits  # [batch_size, num_labels]\n",
    "    batch_preds = torch.argmax(logits, dim=1)  # [batch_size]\n",
    "    predicted_labels.extend(batch_preds.tolist())  # [0, 1, 2, ...]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = true_labels\n",
    "y_pred = predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       639\n",
      "           1       0.96      0.99      0.98       628\n",
      "\n",
      "    accuracy                           0.98      1267\n",
      "   macro avg       0.98      0.98      0.98      1267\n",
      "weighted avg       0.98      0.98      0.98      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "predicted_labels = []\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch_texts = texts[i:i + batch_size]\n",
    "    inputs = bert_tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    outputs = bert_model(**inputs)\n",
    "\n",
    "    logits = outputs.logits  # [batch_size, num_labels]\n",
    "    batch_preds = torch.argmax(logits, dim=1)  # [batch_size]\n",
    "    predicted_labels.extend(batch_preds.tolist()) # [0, 1, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       639\n",
      "           1       0.99      0.99      0.99       628\n",
      "\n",
      "    accuracy                           0.99      1267\n",
      "   macro avg       0.99      0.99      0.99      1267\n",
      "weighted avg       0.99      0.99      0.99      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = true_labels\n",
    "y_pred = predicted_labels\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "predicted_labels = []\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch_texts = texts[i:i + batch_size]\n",
    "    inputs = albert_tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    outputs = albert_model(**inputs)\n",
    "\n",
    "    logits = outputs.logits  # [batch_size, num_labels]\n",
    "    batch_preds = torch.argmax(logits, dim=1)  # [batch_size]\n",
    "    predicted_labels.extend(batch_preds.tolist()) # [0, 1, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       639\n",
      "           1       0.98      1.00      0.99       628\n",
      "\n",
      "    accuracy                           0.99      1267\n",
      "   macro avg       0.99      0.99      0.99      1267\n",
      "weighted avg       0.99      0.99      0.99      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = true_labels\n",
    "y_pred = predicted_labels\n",
    "print(classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
